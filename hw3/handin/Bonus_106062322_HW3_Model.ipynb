{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6LilVrg10J2"
   },
   "source": [
    "## Predict Final Result Block\n",
    "跑完這個 block 以後，就可以得到 final CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-U9I8F13143K",
    "outputId": "985f3f25-fefc-41a7-8617-cf54ea4a2310"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/457 [00:00<?, ?it/s]/usr/local/anaconda3/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n",
      "100%|██████████| 457/457 [00:00<00:00, 825.86it/s]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "\n",
    "df = pd.read_csv(\"./hw3_meta/prediction_example.csv\")\n",
    "patientList = df['PATIENT ID'].tolist()\n",
    "\n",
    "# CXR Data Preprocessing\n",
    "data = []\n",
    "for id in tqdm(patientList):\n",
    "  filepath = './predicting_images/' + str(id) + '.jpg'\n",
    "  img = keras.preprocessing.image.load_img(filepath, grayscale=True, target_size=(64, 64))\n",
    "  img = np.array(img)\n",
    "  data.append(img)\n",
    "data = np.array(data).reshape(-1, 64, 64, 1)\n",
    "\n",
    "CXR_Dataset = data / 255.0\n",
    "\n",
    "# EHR Data Preprocessing\n",
    "data = pd.read_csv('./hw3_meta/fixed_test.csv')\n",
    "\n",
    "# Create Dataframe\n",
    "df = pd.DataFrame(data)\n",
    "df = df[df['PATIENT ID'].isin(patientList)]\n",
    "df = df.drop(columns=['admission_datetime', 'PATIENT ID', 'sex'])\n",
    "\n",
    "# Since ed_diagnosis is STRING LABEL, we need to transform the string to integer label for further training\n",
    "df = pd.get_dummies(df)\n",
    "\n",
    "# Fill NAN values\n",
    "headerList = df.columns.values.tolist()\n",
    "filteredList = list(filter(lambda name: 'pmhx' in name, headerList)) # need to fill mode\n",
    "otherList = list(filter(lambda name: 'pmhx' not in name, headerList)) # need to fill mean\n",
    "\n",
    "for filteredCol in filteredList:\n",
    "  df[filteredCol].fillna(df[filteredCol].mode()[0], inplace=True)\n",
    "\n",
    "for otherCol in otherList:\n",
    "  df[otherCol].fillna(df[otherCol].mean(), inplace=True)\n",
    "\n",
    "EHR_Dataset = df.to_numpy()\n",
    "\n",
    "loadedModel = keras.models.load_model(\"./hw3_meta/bonus_model-16-0.999-0.31-0.55-f1-0.39.h5\")\n",
    "predict_ans = loadedModel.predict([CXR_Dataset, EHR_Dataset])\n",
    "predict_ans = predict_ans.round() # Force output to [0, 1]\n",
    "\n",
    "with open('Bonus_106062322.csv', 'w', newline='') as csvfile:\n",
    "  writer = csv.writer(csvfile)\n",
    "  writer.writerow(['PATIENT ID', 'hospital_outcome'])\n",
    "  for idx, val in enumerate(predict_ans):\n",
    "    writer.writerow([ patientList[idx], int(predict_ans[idx][0])])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ilo-S-2hYMrl"
   },
   "source": [
    "## HW3: [BONUS] CNN implementation\n",
    "**It's unnecessary to run if only need to generate predict result!**\n",
    "\n",
    "\n",
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kxUTcBrW0piD",
    "outputId": "e38e3fdf-9fdf-4967-bbee-e9e499c8e163"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7dIByc72z8oQ",
    "outputId": "65df48ed-e4f8-46da-9b6f-dc139c95d5f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1393 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n",
      "100%|██████████| 1393/1393 [00:03<00:00, 424.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image size: (1393, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.keras import layers, models, preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"/content/drive/My Drive/ML-Homework/hw3/cxr_label_train.csv\")\n",
    "patient_ids = df['PATIENT ID'].tolist()\n",
    "label = np.array(df['hospital_outcome']).reshape(-1, 1)\n",
    "\n",
    "data = []\n",
    "for id in tqdm(patient_ids):\n",
    "  filepath = '/content/drive/My Drive/ML-Homework/hw3/training_images/' + str(id) + '.jpg'\n",
    "  img = preprocessing.image.load_img(filepath, grayscale=True, target_size=(64, 64))\n",
    "  img = np.array(img)\n",
    "  data.append(img)\n",
    "# 64x64 image size 1 -> color dimension\n",
    "data = np.array(data).reshape(-1, 64, 64, 1)\n",
    "\n",
    "data = data / 255.0\n",
    "\n",
    "print(f\"image size: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HpUB_p2AsSZ_",
    "outputId": "22baf0f0-0e42-41dd-b017-1414780ece3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hw2 size: (1393, 49)\n"
     ]
    }
   ],
   "source": [
    "# Create Dataframe\n",
    "hw2data = pd.read_csv('/content/drive/My Drive/ML-Homework/hw3/hm_hospitales_covid_structured_30d_train.csv')\n",
    "df = pd.DataFrame(hw2data)\n",
    "hw2PatientList = df['PATIENT ID'].to_numpy()\n",
    "df = df.drop(columns=['admission_datetime', 'PATIENT ID', 'sex'])\n",
    "\n",
    "# Since ed_diagnosis is STRING LABEL, we need to transform the string to integer label for further training\n",
    "df = pd.get_dummies(df)\n",
    "\n",
    "# Fill NAN values\n",
    "headerList = df.columns.values.tolist()\n",
    "filteredList = list(filter(lambda name: 'pmhx' in name, headerList)) # need to fill mode\n",
    "otherList = list(filter(lambda name: 'pmhx' not in name, headerList)) # need to fill mean\n",
    "\n",
    "for filteredCol in filteredList:\n",
    "  df[filteredCol].fillna(df[filteredCol].mode()[0], inplace=True)\n",
    "\n",
    "for otherCol in otherList:\n",
    "  df[otherCol].fillna(df[otherCol].mean(), inplace=True)\n",
    "\n",
    "hw2FilteredDataset = []\n",
    "for idx, patientId in enumerate(hw2PatientList):\n",
    "  if patientId in patient_ids:\n",
    "    hw2FilteredDataset.append(df.iloc[idx])\n",
    "\n",
    "hw2FilteredDataset = np.array(hw2FilteredDataset)\n",
    "print(f\"hw2 size: {hw2FilteredDataset.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3v5rYByIyThP",
    "outputId": "704de710-77a3-48da-e8fd-d04745a0ddcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image training size: (1114, 64, 64, 1)\n",
      "hw2 training size: (1114, 49)\n",
      "label training size: (1114, 1)\n",
      "Distinct numbers: {0: 981, 1: 133}  133\n",
      "hw2 augmented numbers: {0: 981, 1: 981}\n",
      "Dead Person Number: (133, 64, 64, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " new hw2 data: (1976, 49)\n",
      "New Distinct numbers: {0: 981, 1: 995}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Train / Test Split\n",
    "TRAIN_TEST_SPLIT_RATIO = 0.2\n",
    "image_training_data, image_validate_data, hw2_training_data, hw2_validate_data, label_training_data, label_validate_data = train_test_split(data, hw2FilteredDataset, label, test_size=TRAIN_TEST_SPLIT_RATIO, random_state=0)\n",
    "\n",
    "print(f\"image training size: {image_training_data.shape}\")\n",
    "print(f\"hw2 training size: {hw2_training_data.shape}\")\n",
    "print(f\"label training size: {label_training_data.shape}\")\n",
    "\n",
    "# Calculate the current distribution of healthy / dead person\n",
    "unique, counts = np.unique(label_training_data, return_counts=True)\n",
    "healthyNum = counts[0]\n",
    "deadNum = counts[1]\n",
    "print(f\"Distinct numbers: {dict(zip(unique, counts))}  {counts[1]}\")\n",
    "\n",
    "# Augment the hw2 dead person\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "smote = SMOTE(ratio='minority')\n",
    "augmented_hw2, augmented_hw2_labels = smote.fit_sample(hw2_training_data, label_training_data)\n",
    "\n",
    "unique, counts = np.unique(augmented_hw2_labels, return_counts=True)\n",
    "print(f\"hw2 augmented numbers: {dict(zip(unique, counts))}\")\n",
    "\n",
    "augmented_dead_hw2 = []\n",
    "for idx, label in enumerate(augmented_hw2_labels):\n",
    "  if label == 1:\n",
    "    augmented_dead_hw2.append(augmented_hw2[idx])\n",
    "\n",
    "# Augment the hw3 image dead images\n",
    "deadImgDataset = []\n",
    "deadlabelDataset = []\n",
    "for idx, label in enumerate(label_training_data):\n",
    "  if label == 1:\n",
    "    deadImgDataset.append(image_training_data[idx])\n",
    "    deadlabelDataset.append(label)\n",
    "\n",
    "deadImgDataset = np.array(deadImgDataset)\n",
    "deadlabelDataset = np.array(deadlabelDataset)\n",
    "\n",
    "print(f\"Dead Person Number: {deadImgDataset.shape}\")\n",
    "\n",
    "# Force to export numpy array \n",
    "# Reference to https://stackoverflow.com/questions/42284873/assign-imagedatagenerator-result-to-numpy-array\n",
    "datagen = ImageDataGenerator(\n",
    "    zca_whitening=False,\n",
    "    rotation_range=5,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.,\n",
    "    zoom_range=0.05,\n",
    "    horizontal_flip=False,\n",
    "    fill_mode='nearest'\n",
    ");\n",
    "\n",
    "newAddCount = 0\n",
    "for x_batch, y_batch in datagen.flow(deadImgDataset, deadlabelDataset, batch_size=32):\n",
    "  image_training_data = np.concatenate((image_training_data, x_batch))\n",
    "  label_training_data = np.concatenate((label_training_data, y_batch))\n",
    "  newAddCount += x_batch.shape[0]\n",
    "  if ((newAddCount + deadNum) > healthyNum): break\n",
    "\n",
    "# Finalize\n",
    "augmented_dead_hw2 = np.array(augmented_dead_hw2)\n",
    "hw2_training_data = np.concatenate((hw2_training_data, augmented_dead_hw2[np.random.choice(len(augmented_dead_hw2), size=newAddCount, replace=False)]))\n",
    "print(f\" new hw2 data: {hw2_training_data.shape}\")\n",
    "\n",
    "unique, counts = np.unique(label_training_data, return_counts=True)\n",
    "print(f\"New Distinct numbers: {dict(zip(unique, counts))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "BMg5WWQTtYDy"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import seaborn\n",
    "# plot ROC curve\n",
    "def plot_roc(label, pred):\n",
    "  fpr, tpr, _ = roc_curve(label, pred)\n",
    "  roc_auc = auc(fpr, tpr)\n",
    "\n",
    "  fig = plt.figure()\n",
    "  lw = 2\n",
    "  plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "  plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "  plt.xlim([0.0, 1.0])\n",
    "  plt.ylim([0.0, 1.0])\n",
    "  plt.xlabel('False Positive Rate')\n",
    "  plt.ylabel('True Positive Rate')\n",
    "  plt.legend(loc=\"lower right\")\n",
    "  plt.show()\n",
    "  return\n",
    "\n",
    "def plot_precision_recall(label, pred):\n",
    "  precision = metrics.precision_score(label, pred)\n",
    "  recall = metrics.recall_score(label, pred)\n",
    "  confusion_metrix = metrics.confusion_matrix(label, pred)\n",
    "  seaborn.heatmap(confusion_metrix, annot=True, fmt=\"d\", cmap=\"YlGnBu\", cbar=False)\n",
    "  plt.show()\n",
    "  print(f\"Precision: {precision}\")\n",
    "  print(f\"Recall: {recall}\")\n",
    "  print(f\"Precision + Recall: {precision + recall}\")\n",
    "  # print(precision, recall)\n",
    "  # print(confusion_metrix)\n",
    "  return\n",
    "\n",
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'])\n",
    "  plt.plot(history.history['val_loss'])\n",
    "  plt.title('Model loss')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Test'], loc='upper right')\n",
    "  plt.show()\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BpgVRFK_2A3e",
    "outputId": "fac519aa-ebd6-429a-feef-6ee106bf84eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 29, 29, 32)   1600        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 49)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 32)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 40)           2000        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 14, 14, 32)   128         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 40)           160         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 6, 6, 32)     9248        batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 40)           0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 6, 6, 32)     128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 40)           1640        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 2, 2, 32)     9248        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 40)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 2, 2, 32)     128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 40)           1640        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 128)          0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 40)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 168)          0           flatten_1[0][0]                  \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 128)          21632       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            129         dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 47,681\n",
      "Trainable params: 47,409\n",
      "Non-trainable params: 272\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def net():\n",
    "  img_data = keras.layers.Input(shape=(64, 64, 1))\n",
    "  num_data = keras.layers.Input(shape=(49))\n",
    "\n",
    "  # image data extraction\n",
    "  x = layers.Conv2D(32, (7, 7), strides=2, input_shape=(64, 64, 1), activation='relu')(img_data)\n",
    "  x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "  x = layers.BatchNormalization()(x)\n",
    "  x = layers.Conv2D(32, (3, 3), strides=2, activation='relu')(x)\n",
    "  x = layers.BatchNormalization()(x)\n",
    "  x = layers.Conv2D(32, (3, 3), strides=2, activation='relu')(x)\n",
    "  x = layers.BatchNormalization()(x)\n",
    "  x = layers.Flatten()(x)\n",
    "  x = keras.Model(inputs=img_data, outputs=x)\n",
    "\n",
    "  # numeric data extraction\n",
    "  y = layers.Dense(40, activation='relu', input_shape=(49,))(num_data)\n",
    "  y = layers.BatchNormalization()(y)\n",
    "  y = layers.Dropout(0.4)(y)\n",
    "  y = layers.Dense(40, activation='relu')(y)\n",
    "  y = layers.Dropout(0.4)(y)\n",
    "  y = layers.Dense(40, activation='relu')(y)\n",
    "  y = layers.Dropout(0.4)(y)\n",
    "  y = keras.Model(inputs=num_data, outputs=y)\n",
    "\n",
    "  # fully connected layer\n",
    "  combined = keras.layers.concatenate([x.output, y.output])\n",
    "  z = keras.layers.Dense(units=128, activation=\"relu\")(combined)\n",
    "  z = keras.layers.Dense(units=1, activation=\"sigmoid\")(z)\n",
    "  model = keras.Model(inputs=[x.input, y.input], outputs=z)\n",
    "  return model\n",
    "\n",
    "model = net()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "7RzwIgp2Wi9n"
   },
   "outputs": [],
   "source": [
    "!rm -rf ./tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K9IuZ-fV-9Pw",
    "outputId": "a1038f50-3229-43fb-f075-223a76900236"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 4s 72ms/step - loss: 0.6129 - precision_1: 0.7600 - recall_1: 0.6530 - val_loss: 9.5170 - val_precision_1: 0.1111 - val_recall_1: 1.0000\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.4026 - precision_1: 0.8479 - recall_1: 0.7957 - val_loss: 5.3422 - val_precision_1: 0.1152 - val_recall_1: 1.0000\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.4097 - precision_1: 0.8159 - recall_1: 0.7955 - val_loss: 1.9573 - val_precision_1: 0.1407 - val_recall_1: 0.9032\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.3588 - precision_1: 0.8585 - recall_1: 0.8082 - val_loss: 1.3381 - val_precision_1: 0.1729 - val_recall_1: 0.7419\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.3206 - precision_1: 0.8752 - recall_1: 0.8210 - val_loss: 0.8928 - val_precision_1: 0.1789 - val_recall_1: 0.5484\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.3526 - precision_1: 0.8411 - recall_1: 0.8258 - val_loss: 1.1311 - val_precision_1: 0.1615 - val_recall_1: 0.6774\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.3219 - precision_1: 0.8446 - recall_1: 0.8537 - val_loss: 1.2605 - val_precision_1: 0.1774 - val_recall_1: 0.7097\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.2717 - precision_1: 0.8767 - recall_1: 0.8599 - val_loss: 0.7902 - val_precision_1: 0.2048 - val_recall_1: 0.5484\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.2599 - precision_1: 0.8898 - recall_1: 0.8644 - val_loss: 0.7671 - val_precision_1: 0.1977 - val_recall_1: 0.5484\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.2361 - precision_1: 0.8899 - recall_1: 0.9085 - val_loss: 1.1269 - val_precision_1: 0.2375 - val_recall_1: 0.6129\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.2470 - precision_1: 0.8959 - recall_1: 0.8843 - val_loss: 0.8711 - val_precision_1: 0.2679 - val_recall_1: 0.4839\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.2578 - precision_1: 0.8898 - recall_1: 0.8674 - val_loss: 0.7795 - val_precision_1: 0.2581 - val_recall_1: 0.5161\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.2125 - precision_1: 0.9211 - recall_1: 0.8975 - val_loss: 1.1602 - val_precision_1: 0.2540 - val_recall_1: 0.5161\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.2053 - precision_1: 0.9270 - recall_1: 0.9013 - val_loss: 1.0570 - val_precision_1: 0.2500 - val_recall_1: 0.4839\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.1493 - precision_1: 0.9436 - recall_1: 0.9271 - val_loss: 1.2584 - val_precision_1: 0.2143 - val_recall_1: 0.5806\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.1340 - precision_1: 0.9659 - recall_1: 0.9440 - val_loss: 1.2079 - val_precision_1: 0.2162 - val_recall_1: 0.5161\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.1480 - precision_1: 0.9511 - recall_1: 0.9362 - val_loss: 1.1546 - val_precision_1: 0.3061 - val_recall_1: 0.4839\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.1460 - precision_1: 0.9369 - recall_1: 0.9354 - val_loss: 2.2783 - val_precision_1: 0.2093 - val_recall_1: 0.5806\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.1184 - precision_1: 0.9645 - recall_1: 0.9540 - val_loss: 1.8963 - val_precision_1: 0.1750 - val_recall_1: 0.4516\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0692 - precision_1: 0.9784 - recall_1: 0.9748 - val_loss: 1.4317 - val_precision_1: 0.1733 - val_recall_1: 0.4194\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 0.0540 - precision_1: 0.9930 - recall_1: 0.9852 - val_loss: 1.2153 - val_precision_1: 0.1935 - val_recall_1: 0.3871\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0435 - precision_1: 0.9892 - recall_1: 0.9888 - val_loss: 1.1292 - val_precision_1: 0.2333 - val_recall_1: 0.4516\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0389 - precision_1: 0.9949 - recall_1: 0.9889 - val_loss: 1.0595 - val_precision_1: 0.2400 - val_recall_1: 0.3871\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.0405 - precision_1: 0.9887 - recall_1: 0.9882 - val_loss: 1.0654 - val_precision_1: 0.2593 - val_recall_1: 0.4516\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0243 - precision_1: 0.9986 - recall_1: 0.9985 - val_loss: 1.0514 - val_precision_1: 0.2745 - val_recall_1: 0.4516\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0296 - precision_1: 0.9996 - recall_1: 0.9929 - val_loss: 1.0506 - val_precision_1: 0.2800 - val_recall_1: 0.4516\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.0274 - precision_1: 0.9926 - recall_1: 0.9985 - val_loss: 1.0745 - val_precision_1: 0.2653 - val_recall_1: 0.4194\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.0213 - precision_1: 0.9990 - recall_1: 0.9979 - val_loss: 1.0637 - val_precision_1: 0.2766 - val_recall_1: 0.4194\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.0232 - precision_1: 0.9892 - recall_1: 0.9993 - val_loss: 1.1070 - val_precision_1: 0.2600 - val_recall_1: 0.4194\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0185 - precision_1: 0.9939 - recall_1: 0.9993 - val_loss: 1.1169 - val_precision_1: 0.2653 - val_recall_1: 0.4194\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0181 - precision_1: 0.9995 - recall_1: 0.9980 - val_loss: 1.1294 - val_precision_1: 0.2653 - val_recall_1: 0.4194\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0247 - precision_1: 0.9931 - recall_1: 0.9971 - val_loss: 1.1354 - val_precision_1: 0.2653 - val_recall_1: 0.4194\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 0.0176 - precision_1: 0.9968 - recall_1: 0.9996 - val_loss: 1.1410 - val_precision_1: 0.2708 - val_recall_1: 0.4194\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 0.0188 - precision_1: 0.9973 - recall_1: 0.9987 - val_loss: 1.1457 - val_precision_1: 0.2708 - val_recall_1: 0.4194\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 0.0186 - precision_1: 0.9983 - recall_1: 0.9998 - val_loss: 1.1484 - val_precision_1: 0.2708 - val_recall_1: 0.4194\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 0.0173 - precision_1: 0.9985 - recall_1: 0.9981 - val_loss: 1.1535 - val_precision_1: 0.2708 - val_recall_1: 0.4194\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 0.0189 - precision_1: 0.9998 - recall_1: 0.9969 - val_loss: 1.1552 - val_precision_1: 0.2708 - val_recall_1: 0.4194\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 0.0205 - precision_1: 0.9957 - recall_1: 0.9989 - val_loss: 1.1559 - val_precision_1: 0.2708 - val_recall_1: 0.4194\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0170 - precision_1: 0.9992 - recall_1: 1.0000 - val_loss: 1.1634 - val_precision_1: 0.2766 - val_recall_1: 0.4194\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 0.0161 - precision_1: 0.9993 - recall_1: 1.0000 - val_loss: 1.1663 - val_precision_1: 0.2766 - val_recall_1: 0.4194\n"
     ]
    }
   ],
   "source": [
    "from keras.metrics import Precision, Recall\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "checkpoint_filepath = \"./tmp/model-{epoch:02d}-{val_loss:.3f}-{val_precision_1:.2f}-{val_recall_1:.2f}.h5\"\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(checkpoint_filepath, save_best_only=False, save_weights_only=False)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[Precision(), Recall()]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x=[image_training_data, hw2_training_data], y=label_training_data,\n",
    "\t  validation_data=([image_validate_data, hw2_validate_data], label_validate_data),\n",
    "    epochs=40,\n",
    "    batch_size=64,\n",
    "    callbacks=[\n",
    "      model_checkpoint,\n",
    "      ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "bLMpMm7h_s40",
    "outputId": "8bc3c8a2-21eb-47e9-ff95-b92281d3c775"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3148148148148148\n",
      "Recall: 0.5483870967741935\n",
      "Precision + Recall: 0.8632019115890084\n",
      "f1 score: 0.39999999999999997\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "loadedModel = keras.models.load_model(\"./bonus_model-16-0.999-0.31-0.55-f1-0.39.h5\")\n",
    "predict_ans = loadedModel.predict([image_validate_data, hw2_validate_data])\n",
    "predict_ans = predict_ans.round() # Force output to [0, 1]\n",
    "plot_precision_recall(label_validate_data, predict_ans)\n",
    "\n",
    "print(f\"f1 score: {metrics.f1_score(label_validate_data, predict_ans)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WgPXhPP6WS2k"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Bonus_106062322_HW3_Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
